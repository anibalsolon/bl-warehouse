#!/usr/bin/env node
const winston = require('winston');
const async = require('async');
const request = require('request');
const fs = require('fs');

const config = require('../api/config');
const logger = new winston.Logger(config.logger.winston);
const db = require('../api/models');

///////////////////////////////////////////////////////////////////////////////////////////////////
//
// TODOs
//
// * Look for finished tasks and archive data
// * Look for failed tasks and report to the user / disable rule?
//

db.init(function(err) {
    if(err) throw err;

	db.Rules.find().exec((err, rules)=>{
		if(err) throw err;
        console.log(JSON.stringify(rules, null, 4));

        async.eachSeries(rules, (rule, next_rule)=>{
            handle_rule(rule, next_rule);
        }, err=>{
            if(err) throw err;
            logger.debug("done with all rules");
            db.disconnect();
        });
	});
});

function handle_rule(rule, cb) {

    var jwt = null;
    var process_date = rule.process_date; //keep old date to compare things against..
    var app = null;
    var subjects = null;

    /* 
    //DEBUG----------------------------------------------------------------------------------------------------------------------------
    //this lets me rerun rule that I just handled
    process_date = new Date("2017-05-01");
    //DEBUG----------------------------------------------------------------------------------------------------------------------------
    */

    //prepare for stage / app / archive
    async.series([
            
        //issue user jwt
        next=>{
            request.get({
                url: config.auth.api+"/jwt/"+rule.user_id, json: true,
                headers: { authorization: "Bearer "+config.auth.jwt },
            }, (err, res, body)=>{
                if(err) return next(err);
                if(res.statusCode != 200) return cb("couldn't obtain user jwt code:"+res.statusCode);
                jwt = body.jwt;
                next();
            });
        },

        //update process date
        next=>{
            //update process_date so that we don't process this again (even if rest of processing fails)
            rule.process_date = new Date();
            rule.save(next);
        },

        //first load the app we might be submitting
        next=>{
            db.Apps.findById(rule.app)
			.populate('outputs.datatype')
            .lean() // so that I can set meta?
			.exec((err, _app)=>{
                if(err) return next(err);
                console.log(_app.name);
                console.dir(_app.config);  
                app = _app;
                //console.log('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa');
                //console.log(JSON.stringify(app.outputs, null, 4));
                //console.log('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa');
                next();
            });
        },

        //enumerate all subjects under rule's project
        next=>{
            logger.debug("enum subjects");
            db.Datasets.find({
                project: rule.input_project,
            })
            .distinct("meta.subject", (err, _subjects)=>{
                if(err) return next(err);
                subjects = _subjects;        
                next();
            });
        },

        //handle all subjects
        next=>{
            async.eachSeries(subjects, handle_subject, next);
        },
    ], err=>{
        if(err) return cb(err);
        logger.debug("done processing all rules");
        cb();
    });

    function handle_subject(subject, next_subject) {
        logger.debug("handling subject", subject);

        //debug
        //fs.writeFileSync("app."+new Date().getTime(), JSON.stringify(app, null, 4));

        //for each input.. see there is any new datasets created since last process_date
        var foundnew = false;
        var inputs = {};
        async.eachSeries(app.inputs, (input, next_input)=>{
            
            var query = {
                project: rule.input_project,
                removed: false,
                datatype: input.datatype,
            }
            if(input.datatype_tags.length > 0) datatype_tags = { $all: input.datatype_tags };
            db.Datasets.findOne(query)
            .populate('datatype')
            .sort('-create_date')
            .lean()
            .exec((err, dataset)=>{
                if(err) return next_input(err);
                if(!dataset) {
                    logger.debug(" no ", input.id);
                    return next_subject(); //doesn't have input.. 
                }
                //console.log(JSON.stringify(dataset, null, 4));
                inputs[input.id] = dataset;

                //see if we spot any dataset that's newer than the rule's last process data (if so, we need to submit)
                if(!process_date || dataset.create_date > process_date) foundnew = true;

                //load status of task that produced this dataset
                if(dataset.prov && dataset.prov.task_id) {
                    //logger.debug("loading task status", dataset.prov.task_id);
                    request.get({
                        url: config.wf.api+"/task", json: true,
                        headers: { authorization: "Bearer "+jwt },
                        qs: {
                            find: JSON.stringify({_id: dataset.prov.task_id}),
                        },
                    }, (err, res, body)=>{
                        if(err) return next_input(err);
                        logger.debug(body);
                        dataset.prov._task = body.tasks[0];
                        next_input();
                    });
                } else {
                    //probably uploaded / imported
                    next_input();
                }
            });
        }, err=>{
            if(err) return cb(err);
            
            //console.log(JSON.stringify(inputs, null, 4));
            if(!foundnew) {
                logger.debug("no new dataset.. move to next subject");
                return next_subject();
            }

            submit_tasks(subject, inputs, next_subject);
        });
        /*
        , err=>{
            if(err) return cb(err);
            logger.info("all done");
        });
        */
    }

    function submit_tasks(subject, inputs, cb) {
        var instance_name = "brainlife.rule."+rule._id+"."+subject;
        var instance = null;
        var task_stage = null;
        var task_app = null;
        var task_out = null;
		var meta = {}; //metadata to store for archived dataset

        //prepare for stage / app / archive
        async.series([

            //look for instance that we can use
            next=>{
                request.get({
                    url: config.wf.api+"/instance", json: true,
                    headers: { authorization: "Bearer "+jwt },
                    qs: {
                        find: JSON.stringify({
                            name: instance_name,
                            //status: {$ne: "removed"},
                            "config.removing": {$exists: false},
                        }),
                    },
                }, (err, res, body)=>{
                    if(err) return next(err);
                    instance = body.instances[0];
                    if(instance) {
                        logger.debug("using instance");
                        logger.debug(JSON.stringify(instance, null, 4));
                    }
                    next();
                });
            },

            //if we don't have the instance, create one
            next=>{
                if(instance) return next();
                logger.debug("creating a new instance");
                request.post({
                    url: config.wf.api+'/instance', json: true, 
                    headers: { authorization: "Bearer "+jwt },
                    body: {
                        name: instance_name,
                        desc: "process for "+instance_name,
                        
                        //TODO let's show under process page so I can debug
                        config: {
                            brainlife: true,
                        }
                    },
                }, (err, res, body)=>{
                    instance = body;
                    next(err);
                });
            },

            //submit input staging task
            next=>{
                //process UI prov..
                var datasets = {};
                for(var input_id in inputs) {
                    var input = inputs[input_id];
                    datasets[input._id] = Object.assign({}, input);
                    datasets[input._id].datatype = datasets[input._id].datatype._id; //unpopulate datatype to keep it clean
                }

                var body = {
                    instance_id: instance._id,
                    name: "brainlife.stage_input",
                    desc: "staging input for subject:"+rule._id+" subject:"+subject,
                    service: "soichih/sca-product-raw",

                    config: {
                        symlink: [], //for datasets that we have tasks for
                        download: [], //for datasets that produced task no longer exists
                        datasets,
                    },
                    deps: [],
                }

                for(var input_id in inputs) {
                    var input = inputs[input_id];
                    var task = input.prov._task;
                    if(task && task.status == 'finished') {
                        //we still have the datasets staged.. just use that
                        body.config.symlink.push({ 
                            src: "../../"+task.instance_id+"/"+task._id+"/"+input.prov.dirname, //TODO - not sure if this is the right path?
                            dest: input_id 
                        }); 
                        body.deps.push(task._id);
                    } else {
                        logger.debug("input dataset:"+input._id+" is no longer staged on task that generated it.."+task._id+"("+task.status+") Need to download it again");
                        body.config.download.push({
                            url: config.warehouse.api+"/dataset/download/"+input._id+"?at="+jwt,
                            untar: "auto",
                            dir: input_id,
                        });
                    }
                }

                request.post({
                    url: config.wf.api+'/task', json: true, 
                    headers: { authorization: "Bearer "+jwt },
                    body,
                }, (err, res, _body)=>{
                    console.log(JSON.stringify(_body, null, 4));
                    task_stage = _body.task;
                    logger.debug("submitted staging task");//, task_stage);
                    next(err);
                });
            },

            next=>{
                //aggregate metadata (TODO - I really need just subject?)
				for(var input_id in inputs) {
					var input = inputs[input_id];
					for(var k in input.meta) {
						meta[k] = input.meta[k];
					}
				}
                next();
            },

            //submit the app task!
            next=>{
                var _config = Object.assign(rule.config, resolve_config(app.config, inputs, task_stage));

                //set some process ui _prov
                _config._prov = {
                    app: app._id,
                    inputs: {},
                }
                for(var input_id in inputs) {
                    var input = inputs[input_id];
                    _config._prov.inputs[input_id] = input._id;
                }
                
                var body = {
                    instance_id: instance._id,
                    name: "brainlife.process",
                    desc: "running applicaiton "+app.name+" for subject:"+rule._id+" subject:"+subject,
                    service: app.github,
                    service_branch: app.github_branch,
                    retry: app.retry,

                    config: _config,
                    deps: [ task_stage._id ], 
                }
                request.post({
                    url: config.wf.api+'/task', json: true, 
                    headers: { authorization: "Bearer "+jwt },
                    body,
                }, (err, res, _body)=>{
                    console.log(JSON.stringify(_body, null, 4));
                    task_app = _body.task;
                    logger.debug("submitted app task", task_app);
                    next(err);
                });
            },

            //submit output organize task
            next=>{
                var symlink = [];
                var output_datasets = {}; //for prov
                console.log("---------------------------------------------------------------------");
                console.log(JSON.stringify(app.outputs, null, 4));
                console.log("---------------------------------------------------------------------");
				app.outputs.forEach(output=>{
					if(output.files) {
						//has output file mapping.. organize symlink file/dir
                        for(var file_id in output.files) {
                            //find datatype file id in datatype definition
                            output.datatype.files.forEach(datatype_file=>{
                                if(datatype_file.id == file_id) {
                                    var name = datatype_file.filename||datatype_file.dirname;
                                    symlink.push({ 
                                        "src": "../"+task_app._id+"/"+output.files[file_id], 
                                        "dest": output.id+"/"+name 
                                    });
                                }
                            });
                        }
					} else {
						//copy everything under taskdir
						symlink.push({"src": "../"+task_app._id, "dest": output.id});
					}

					output_datasets[output.id] = Object.assign({}, output, {
                        meta,
                        datatype: output.datatype._id, //override to unpopulate
                        
                        //if this is set, handle_task will auto-archive output datasets
                        archive: {
                            project: rule.output_project,  
                            tags: rule.output_tags[output.id], 
                        }
                    }); 
                    //console.log(JSON.stringify(output_datasets, null, 4));
				});

                //for process ui _prov
                var _prov = {
                    app: app._id,
                    output_datasets,
                };
                    
                //submit task
                request.post({
                    url: config.wf.api+'/task', json: true, 
                    headers: { authorization: "Bearer "+jwt },
                    body: {
                        instance_id: instance._id,
                        name: "brainlife.stage_output",
                        desc: "staging output for subject:"+rule._id+" subject:"+subject,
                        service: "soichih/sca-product-raw",
                        config: { symlink, _prov },
                        deps: [ task_app._id ],
                    },
                }, (err, res, _body)=>{
                    console.log(JSON.stringify(_body, null, 4));
                    task_out = _body.task;
                    logger.debug("submitted out task", task_out);
                    next(err);
                });
            },
        ], cb);
    }
}

function resolve_config(config, inputs, task_stage) {
    function walk(node, out) {
        for(var k in node) {
            var v = node[k];
            if(v.type === undefined) {
                //must be grouping object.. traverse to child 
                console.log("groupingn ", k);
                out[k] = {};
                walk(v, out[k]);
                continue;
            }
            switch(v.type) {
            case "input":
                var dataset = inputs[v.input_id];
                //find file
                dataset.datatype.files.forEach(file=>{
                    if(file.id == v.file_id) {
                        out[k] = "../"+task_stage._id+"/"+v.input_id+"/"+(file.filename||file.dirname);
                    }
                });
                break;
            case "integer":
            case "string":
                //scalar configs are handled by the user
            }
        }
        return out;
    }
    return walk(config, {});
}

